{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "DM_Assignment_5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hi0HXI_9M8lY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1fee409-bf13-4dc9-bb2f-1cc2efc5c03a"
      },
      "source": [
        "!pip install einops"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting einops\n",
            "  Downloading https://files.pythonhosted.org/packages/5d/a0/9935e030634bf60ecd572c775f64ace82ceddf2f504a5fd3902438f07090/einops-0.3.0-py2.py3-none-any.whl\n",
            "Installing collected packages: einops\n",
            "Successfully installed einops-0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hc6X4fRDKP-j"
      },
      "source": [
        "#구현하는 모델에서 쓰이는 모든 activation함수는 정의하여 드린 GELU 함수를 사용해야함.\n",
        "#MultiHeadAttention에서 Head로 나눌때, 이미지를 patch로자른후 sequence로 만들때 Rearrange함수를 사용하면 편리함.(사용하지 않으셔도 됩니다)\n",
        "#CIFAR10에 대한 test accuracy가 60프로 이상인 ViT모델을 만드시오.\n",
        "import tensorflow as tf\n",
        "from einops.layers.tensorflow import Rearrange\n",
        "from tensorflow.keras.activations import gelu\n",
        "GELU = lambda x : gelu(x)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrJci74oNV2m"
      },
      "source": [
        "#논문[1]에서 설명하는 MultiHeadAttention을 만들어라.\n",
        "class MultiHeadedAttention(tf.keras.Model):\n",
        "    #dimension - 모델의 dimension(MHA를 거친 후의 dimension)\n",
        "    def __init__(self, dimension, heads=8):\n",
        "        super(MultiHeadedAttention, self).__init__()\n",
        "        ############Write your code Here############\n",
        "        self.heads = heads\n",
        "        # scale attention value with 1/sqrt(dk)\n",
        "        self.scale = dimension ** -0.5\n",
        "\n",
        "        # Multihead attention input dimension => dk + dk + dv (dk == dv) \n",
        "        self.multihead_in = tf.keras.layers.Dense(dimension * 3, use_bias=False)\n",
        "        # yield dv dimensional output\n",
        "        self.multihead_out = tf.keras.layers.Dense(dimension)\n",
        "        \n",
        "        # b = batch size, n = number of patches, qkv = query key value, h = height \n",
        "        self.rearrange_attention = Rearrange(\n",
        "            'b n (qkv h d) -> qkv b h n d', qkv=3, h=self.heads)\n",
        "        self.rearrange_output = Rearrange('b h n d -> b n (h d)')\n",
        "        ############################################\n",
        "    def call(self, inputs):\n",
        "        output = None\n",
        "        ############Write your code Here############\n",
        "        qkv = self.multihead_in(inputs)\n",
        "        qkv = self.rearrange_attention(qkv)\n",
        "        \n",
        "        # query key value\n",
        "        query = qkv[0]\n",
        "        key = qkv[1]\n",
        "        value = qkv[2]\n",
        "\n",
        "        dot_product = tf.einsum('bhid,bhjd->bhij', query, key) * self.scale\n",
        "        attention = tf.nn.softmax(dot_product, axis=-1)\n",
        "        output = tf.einsum('bhij,bhjd->bhid', attention, value)\n",
        "        output = self.rearrange_output(output)\n",
        "        output = self.multihead_out(output)\n",
        "        ############################################\n",
        "        return output\n",
        "\n",
        "#인자로 받은 residual_function을 사용하여 real_function값을 return하여주는 Class를 만들어라.(call함수 참고)\n",
        "class ResidualBlock(tf.keras.Model):\n",
        "    def __init__(self, residual_function):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        ############Write your code Here############\n",
        "        self.residual_function = residual_function\n",
        "        ############################################\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.residual_function(inputs) + inputs\n",
        "\n",
        "#인자로 받은 normfunction에 들어가기전에 LayerNormalization을 해주는 Class를 만들어라.(call함수 참고)\n",
        "class NormalizationBlock(tf.keras.Model):\n",
        "    def __init__(self, norm_function, epsilon=1e-5):\n",
        "        super(NormalizationBlock, self).__init__()\n",
        "        ############Write your code Here############\n",
        "        self.norm_function = norm_function\n",
        "        self.norm = tf.keras.layers.LayerNormalization(epsilon=1e-5)\n",
        "        ############################################\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.norm_function(self.norm(inputs))\n",
        "\n",
        "#논문[1]에서의 MLPBlock을 만들어라.\n",
        "class MLPBlock(tf.keras.Model):\n",
        "    #output_dimension - MLPBlock의 output dimension\n",
        "    #hidden_dimension - MLPBlock의 hidden layer dimension\n",
        "    def __init__(self, output_dimension, hidden_dimension):\n",
        "        super(MLPBlock, self).__init__()\n",
        "        ############Write your code Here############\n",
        "        # fully connected layer to produce outputs of dmodel\n",
        "        self.fc_1 = tf.keras.layers.Dense(hidden_dimension)\n",
        "        self.fc_2 = tf.keras.layers.Dense(output_dimension)\n",
        "        self.dropout = tf.keras.layers.Dropout(0.1)\n",
        "        ############################################\n",
        "\n",
        "    def call(self, inputs):\n",
        "        output = None\n",
        "        ############Write your code Here############\n",
        "        output = self.fc_1(inputs)\n",
        "        output = GELU(output)\n",
        "        output = self.dropout(output)\n",
        "        output = self.fc_2(output)\n",
        "        ############################################\n",
        "        return output\n",
        "\n",
        "#논문[1]을 읽고 TransformerEncoder를 위에서 정의한 class들을 사용하여 만들어라.\n",
        "class TransformerEncoder(tf.keras.Model):\n",
        "    #dimension - 모델의 dimension(MHA를 거친 후의 dimension), heads - MHA에서 head의 개수\n",
        "    #depth - encoder layer의 개수, mlp_dimension - MLP block의 hidden layer의 dimension\n",
        "    def __init__(self, dimension, depth, heads, mlp_dimension): \n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        layers_ = []\n",
        "        for _ in range(depth):\n",
        "            ############Write your code Here############\n",
        "            layers_.extend([\n",
        "                NormalizationBlock(ResidualBlock(MultiHeadedAttention(dimension, heads=heads))),\n",
        "                tf.keras.layers.Dropout(0.1),\n",
        "                NormalizationBlock(ResidualBlock(MLPBlock(dimension, mlp_dimension))),\n",
        "                tf.keras.layers.Dropout(0.1)\n",
        "            ])\n",
        "            ############################################\n",
        "        self.layers_ = tf.keras.Sequential(layers_)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.layers_(inputs)\n",
        "\n",
        "#논문[2]를 읽고 ViT모델을 위에서 정의한 class들을 사용하여 만들어라.\n",
        "class ImageTransformer(tf.keras.Model):\n",
        "    #image_size - 이미지의 W==H의 크기(int), patch_size - 이미지를 쪼갤 patch의 크기(int)\n",
        "    #n_classes - 최종 class의 개수, batch_size - 배치사이즈\n",
        "    #dimension - 모델의 dimension(MHA를 거친 후의 dimension), depth - encoder layer의 개수\n",
        "    #heads - MHA에서 head의 개수, mlp_dimension - MLP block의 hidden layer의 dimension\n",
        "    #channel - input image에 대한 channel의 수\n",
        "    def __init__(\n",
        "            self, image_size, patch_size, n_classes, batch_size,\n",
        "            dimension, depth, heads, mlp_dimension, channels=3):\n",
        "        super(ImageTransformer, self).__init__()\n",
        "        assert image_size % patch_size == 0, 'invalid patch size for image size'\n",
        "\n",
        "        num_patches = (image_size // patch_size) ** 2\n",
        "        self.patch_size = patch_size\n",
        "        self.dimension = dimension\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.positional_embedding = self.add_weight(\n",
        "            \"position_embeddings\", shape=[num_patches + 1, dimension],\n",
        "            initializer=tf.keras.initializers.RandomNormal(), dtype=tf.float32\n",
        "        )\n",
        "        self.classification_token = self.add_weight(\n",
        "            \"classification_token\", shape=[1, 1, dimension],\n",
        "            initializer=tf.keras.initializers.RandomNormal(), dtype=tf.float32\n",
        "        )\n",
        "        ############Write your code Here############\n",
        "        # divide image into patches (p1 * p2)\n",
        "        self.rearrange = Rearrange(\n",
        "            'b c (h p1) (w p2) -> b (h w) (p1 p2 c)',\n",
        "            p1=self.patch_size, p2=self.patch_size\n",
        "        )\n",
        "\n",
        "        # patch -> embedding (flatten patches)\n",
        "        self.patch_to_embedding = tf.keras.layers.Dense(dimension)\n",
        "        self.transformer = TransformerEncoder(dimension, depth, heads, mlp_dimension)\n",
        "        self.classification_identity = tf.identity\n",
        "        self.fc_1 = tf.keras.layers.Dense(mlp_dimension)\n",
        "        self._output = tf.keras.layers.Dense(n_classes)\n",
        "        ############################################\n",
        "\n",
        "    def call(self, inputs):\n",
        "        output = None\n",
        "        ############Write your code Here############\n",
        "        shapes = tf.shape(inputs)\n",
        "        y = self.rearrange(inputs)\n",
        "        y = self.patch_to_embedding(y)\n",
        "\n",
        "        cls_tokens = tf.broadcast_to(\n",
        "            self.classification_token,\n",
        "            (shapes[0], 1, self.dimension)\n",
        "        )\n",
        "        # add class embeddings\n",
        "        y = tf.concat((cls_tokens, y), axis=1)\n",
        "        # add positional embeddings\n",
        "        y += self.positional_embedding\n",
        "        # encoder: multi-head -> normalization -> residual -> feed forward -> normalization -> residual\n",
        "        y = self.transformer(y)\n",
        "        y = self.classification_identity(y[:, 0])\n",
        "        # MLP head\n",
        "        y = self.fc_1(y)\n",
        "        y = GELU(y)\n",
        "        output = self._output(y)\n",
        "        ############################################\n",
        "        return output"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAydwOELeFba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d1264c8-1493-4f37-bcb7-b9f614c3987f"
      },
      "source": [
        "from tensorflow.keras import datasets\n",
        "# Download and prepare the CIFAR10 dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "############Write your code Here############\n",
        "train_images = tf.cast(train_images, dtype=tf.float32) / 255.\n",
        "test_images = tf.cast(test_images, dtype=tf.float32) / 255.\n",
        "############################################\n",
        "# Make image shape (BS, H, W, C) to (BS, C, H, W)\n",
        "############Write your code Here############\n",
        "train_images = tf.transpose(train_images, [0, 3, 1, 2])\n",
        "test_images = tf.transpose(test_images, [0, 3, 1, 2])\n",
        "############################################\n",
        "\n",
        "#Initialize your model\n",
        "#Initialize optimizer and loss and compile it to the model\n",
        "############Write your code Here############\n",
        "model = ImageTransformer(\n",
        "        image_size=32, patch_size=2, n_classes=10, batch_size=64,\n",
        "        dimension=64, depth=3, heads=8, mlp_dimension=256\n",
        "    )\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "cross_entropy_loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction=tf.keras.losses.Reduction.NONE\n",
        "    )\n",
        "model.compile(optimizer=optimizer, loss=cross_entropy_loss, metrics=['accuracy'])\n",
        "############################################\n",
        "\n",
        "\n",
        "#Train your model\n",
        "############Write your code Here############\n",
        "model.fit(train_images, train_labels, batch_size=64, epochs=100)\n",
        "############################################\n",
        "print('==============Training Finished===============')\n",
        "\n",
        "#Evaluate your test samples\n",
        "accuracy = 0\n",
        "############Write your code Here############\n",
        "_, accuracy = model.evaluate(test_images, test_labels)\n",
        "accuracy = accuracy * 100\n",
        "############################################\n",
        "\n",
        "print('Test Accuracy :', accuracy)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n",
            "Epoch 1/100\n",
            "782/782 [==============================] - 50s 56ms/step - loss: 1.7939 - accuracy: 0.3173\n",
            "Epoch 2/100\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 1.4150 - accuracy: 0.4799\n",
            "Epoch 3/100\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 1.2742 - accuracy: 0.5379\n",
            "Epoch 4/100\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 1.1823 - accuracy: 0.5717\n",
            "Epoch 5/100\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 1.1180 - accuracy: 0.5994\n",
            "Epoch 6/100\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 1.0639 - accuracy: 0.6215\n",
            "Epoch 7/100\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 1.0191 - accuracy: 0.6377\n",
            "Epoch 8/100\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 0.9825 - accuracy: 0.6484\n",
            "Epoch 9/100\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 0.9465 - accuracy: 0.6644\n",
            "Epoch 10/100\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 0.9229 - accuracy: 0.6717\n",
            "Epoch 11/100\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 0.8944 - accuracy: 0.6844\n",
            "Epoch 12/100\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 0.8666 - accuracy: 0.6953\n",
            "Epoch 13/100\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 0.8455 - accuracy: 0.7012\n",
            "Epoch 14/100\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 0.8274 - accuracy: 0.7090\n",
            "Epoch 15/100\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 0.8071 - accuracy: 0.7162\n",
            "Epoch 16/100\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 0.7870 - accuracy: 0.7223\n",
            "Epoch 17/100\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 0.7697 - accuracy: 0.7287\n",
            "Epoch 18/100\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 0.7542 - accuracy: 0.7350\n",
            "Epoch 19/100\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 0.7346 - accuracy: 0.7403\n",
            "Epoch 20/100\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 0.7182 - accuracy: 0.7462\n",
            "Epoch 21/100\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 0.7068 - accuracy: 0.7509\n",
            "Epoch 22/100\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 0.6945 - accuracy: 0.7557\n",
            "Epoch 23/100\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 0.6768 - accuracy: 0.7623\n",
            "Epoch 24/100\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 0.6672 - accuracy: 0.7634\n",
            "Epoch 25/100\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 0.6559 - accuracy: 0.7692\n",
            "Epoch 26/100\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 0.6355 - accuracy: 0.7742\n",
            "Epoch 27/100\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 0.6342 - accuracy: 0.7767\n",
            "Epoch 28/100\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 0.6231 - accuracy: 0.7801\n",
            "Epoch 29/100\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 0.6094 - accuracy: 0.7839\n",
            "Epoch 30/100\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 0.5969 - accuracy: 0.7888\n",
            "Epoch 31/100\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 0.5900 - accuracy: 0.7900\n",
            "Epoch 32/100\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 0.5752 - accuracy: 0.7972\n",
            "Epoch 33/100\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 0.5673 - accuracy: 0.7989\n",
            "Epoch 34/100\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 0.5554 - accuracy: 0.8025\n",
            "Epoch 35/100\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 0.5513 - accuracy: 0.8039\n",
            "Epoch 36/100\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 0.5334 - accuracy: 0.8089\n",
            "Epoch 37/100\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 0.5272 - accuracy: 0.8116\n",
            "Epoch 38/100\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 0.5195 - accuracy: 0.8144\n",
            "Epoch 39/100\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 0.5074 - accuracy: 0.8219\n",
            "Epoch 40/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.4998 - accuracy: 0.8229\n",
            "Epoch 41/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.4964 - accuracy: 0.8246\n",
            "Epoch 42/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.4828 - accuracy: 0.8299\n",
            "Epoch 43/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.4787 - accuracy: 0.8313\n",
            "Epoch 44/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.4716 - accuracy: 0.8308\n",
            "Epoch 45/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.4649 - accuracy: 0.8343\n",
            "Epoch 46/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.4582 - accuracy: 0.8349\n",
            "Epoch 47/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.4472 - accuracy: 0.8414\n",
            "Epoch 48/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.4440 - accuracy: 0.8430\n",
            "Epoch 49/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.4337 - accuracy: 0.8454\n",
            "Epoch 50/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.4312 - accuracy: 0.8471\n",
            "Epoch 51/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.4215 - accuracy: 0.8482\n",
            "Epoch 52/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.4125 - accuracy: 0.8538\n",
            "Epoch 53/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.4091 - accuracy: 0.8561\n",
            "Epoch 54/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.4037 - accuracy: 0.8558\n",
            "Epoch 55/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.3912 - accuracy: 0.8601\n",
            "Epoch 56/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.3988 - accuracy: 0.8580\n",
            "Epoch 57/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.3880 - accuracy: 0.8630\n",
            "Epoch 58/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.3795 - accuracy: 0.8647\n",
            "Epoch 59/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.3741 - accuracy: 0.8660\n",
            "Epoch 60/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.3694 - accuracy: 0.8666\n",
            "Epoch 61/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.3713 - accuracy: 0.8669\n",
            "Epoch 62/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.3584 - accuracy: 0.8722\n",
            "Epoch 63/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.3554 - accuracy: 0.8721\n",
            "Epoch 64/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.3529 - accuracy: 0.8734\n",
            "Epoch 65/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.3513 - accuracy: 0.8734\n",
            "Epoch 66/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.3431 - accuracy: 0.8762\n",
            "Epoch 67/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.3346 - accuracy: 0.8800\n",
            "Epoch 68/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.3366 - accuracy: 0.8806\n",
            "Epoch 69/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.3306 - accuracy: 0.8807\n",
            "Epoch 70/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.3273 - accuracy: 0.8807\n",
            "Epoch 71/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.3200 - accuracy: 0.8855\n",
            "Epoch 72/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.3167 - accuracy: 0.8861\n",
            "Epoch 73/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.3146 - accuracy: 0.8878\n",
            "Epoch 74/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.3089 - accuracy: 0.8895\n",
            "Epoch 75/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.3097 - accuracy: 0.8899\n",
            "Epoch 76/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.3012 - accuracy: 0.8923\n",
            "Epoch 77/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.2991 - accuracy: 0.8929\n",
            "Epoch 78/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.2924 - accuracy: 0.8950\n",
            "Epoch 79/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.2968 - accuracy: 0.8942\n",
            "Epoch 80/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.2874 - accuracy: 0.8952\n",
            "Epoch 81/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.2838 - accuracy: 0.8990\n",
            "Epoch 82/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.2873 - accuracy: 0.8950\n",
            "Epoch 83/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.2784 - accuracy: 0.9008\n",
            "Epoch 84/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.2783 - accuracy: 0.8994\n",
            "Epoch 85/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.2721 - accuracy: 0.9034\n",
            "Epoch 86/100\n",
            "782/782 [==============================] - 44s 56ms/step - loss: 0.2718 - accuracy: 0.9019\n",
            "Epoch 87/100\n",
            "782/782 [==============================] - 43s 56ms/step - loss: 0.2654 - accuracy: 0.9044\n",
            "Epoch 88/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.2609 - accuracy: 0.9062\n",
            "Epoch 89/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.2588 - accuracy: 0.9072\n",
            "Epoch 90/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.2607 - accuracy: 0.9068\n",
            "Epoch 91/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.2514 - accuracy: 0.9093\n",
            "Epoch 92/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.2551 - accuracy: 0.9080\n",
            "Epoch 93/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.2531 - accuracy: 0.9092\n",
            "Epoch 94/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.2501 - accuracy: 0.9104\n",
            "Epoch 95/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.2475 - accuracy: 0.9122\n",
            "Epoch 96/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.2464 - accuracy: 0.9110\n",
            "Epoch 97/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.2442 - accuracy: 0.9126\n",
            "Epoch 98/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.2381 - accuracy: 0.9142\n",
            "Epoch 99/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.2394 - accuracy: 0.9135\n",
            "Epoch 100/100\n",
            "782/782 [==============================] - 43s 55ms/step - loss: 0.2356 - accuracy: 0.9156\n",
            "==============Training Finished===============\n",
            "313/313 [==============================] - 5s 13ms/step - loss: 1.6508 - accuracy: 0.6647\n",
            "Test Accuracy : 66.46999716758728\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}